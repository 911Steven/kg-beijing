{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# week2 Assignment\n",
    "\n",
    "## 邮件结构\n",
    "\n",
    "- 将邮件的存储格式分为以下几部分\n",
    "   - 'Metadata': 这部分包含从MIME头提取的信息, 如'From', 'Receive', 'Send_time', 'Subject'等等\n",
    "   - 'Content': 这部分会包含所有的内容信息, 如'Body_text', 'Body_html', 'Recite', 'Attachment', 'Signature'等等\n",
    "   - 'Entities': 包含邮件中提到的各种实体, 如'Name', 'Organization', 'Time', 'Position', 'Tel'\n",
    "   - 'Relation': 包含邮件内的各种关系, 如邮件之间的关系, 邮件内容的语义关系.\n",
    "\n",
    "## 思路\n",
    "\n",
    "- 利用flanker提取MIME头, 将信息初步提取, 这是可以完成'Metadata'部分信息的提取\n",
    "- 利用Regex将邮件内容分解, 段落, 引用, 附件, 签名档一次提取出来.\n",
    "- 利用NLTK, jieba等分词工具, 进一步细化, 提取各个实体.\n",
    "- 最后进行更深入的关系分析提取.\n",
    "- 这样层层递进, 逐渐深入,\n",
    "\n",
    "\n",
    "## 难点\n",
    "\n",
    "- 分段有可能比较混乱, 这里可能会花一点时间\n",
    "- 引用通过'>','>>'来判断\n",
    "- 签名档因为比较复杂, 格式不一, 甚至有的没有, 有的特别简单, 信息不够全面\n",
    "- 关系表示, 邮件内部, 邮件外部\n",
    "\n",
    "## Tips\n",
    "\n",
    "- 邮件的结尾都是--boundary--\n",
    "    - 此处有坑\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import flanker\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from flanker import mime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(filename='2013-11.mbx'):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.read()\n",
    "    f.close()\n",
    "    data_list = filter(None, re.split(r'From\\s([\\w+.?]+@(\\w+\\.)+(\\w+))', data))  #  \n",
    "    # Here I have to add twice for-loop, I haven't analyse the reason\n",
    "    for data in data_list:\n",
    "        if len(str(data)) < 500:\n",
    "            data_list.remove(data)\n",
    "    for data in data_list:\n",
    "        if len(str(data)) < 500:\n",
    "            data_list.remove(data)\n",
    "    return data_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_list = prepare_data('2013-11.mbx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_headers(msg_string):\n",
    "    mime_dict = {}\n",
    "    msg = mime.from_string(msg_string)\n",
    "    msg_list = msg.headers.items()\n",
    "    mime_keys = ['From', 'Date', 'Cc', 'To', 'Subject', ]\n",
    "    for item in msg_list:\n",
    "        if item[0] in mime_keys:\n",
    "            mime_dict[item[0]] = item[1]\n",
    "    return mime_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cc': u'\\u4e2d\\u6587HTML5\\u540c\\u6a02\\u6703ML <public-html-ig-zh@w3.org>',\n",
       " 'Date': u'Wed, 6 Nov 2013 20:09:11 +0800',\n",
       " 'From': u'\\u8463\\u798f\\u8208 Bobby Tung <bobbytung@wanderer.tw>',\n",
       " 'Subject': u'Re: \\u95dc\\u65bc<cite>\\u5143\\u7d20\\u6700\\u8fd1\\u7684\\u5b9a\\u7fa9\\u4fee\\u6539',\n",
       " 'To': u'Yijun Chen <ethantw@me.com>'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_headers(data_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_content(message_string):\n",
    "    \n",
    "    content_dict = {}\n",
    "    p = re.compile(ur'\\\"?([\\w\\s\\(\\)]+|[\\x80-\\xff]+)\\\"?\\s<')\n",
    "    msg = mime.from_string(message_string)   \n",
    "    for part in msg.parts:\n",
    "        content_dict[str(part)] = part.body\n",
    "    return content_dict\n",
    "    # key 未修正, 直接用了带()的值, 附件也未区分, 直接根据content-type有什么添加什么\n",
    "    # 编码可能有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content_dict = extract_content(data_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode characters in position 0-3: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-0f1a4cc2447e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mbody_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'body.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbody_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode characters in position 0-3: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "body_list = []\n",
    "for message_string in data_list:\n",
    "    msg = mime.from_string(message_string)   \n",
    "    for part in msg.parts:\n",
    "        if part.body:\n",
    "            body_list.append(str(part.body))\n",
    "with open('body.txt', 'a') as ff:\n",
    "    for item in body_list:\n",
    "        ff.write(item)\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_name_list(data_list):\n",
    "    name_list = []\n",
    "    p = re.compile(ur'\\\"?([\\w\\s\\(\\)]+|[\\x80-\\xff]+)\\\"?\\s<')\n",
    "    for message_string in data_list:\n",
    "        msg = mime.from_string(message_string)\n",
    "        for item in msg.headers.items():\n",
    "            if item[0] == 'From':\n",
    "                name = p.search(item[1].encode('utf-8')).group(1)\n",
    "                name_list.append(name)\n",
    "    name_list = list(set(name_list))\n",
    "    name_list += ['Cindy', 'Kenny', 'Chen Yijun', 'Chunming', '-ambrose']\n",
    "    name_list.remove('com')\n",
    "    name_list.remove(' Chunming')\n",
    "    name_list.remove(' Bobby Tung')\n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ambrose LI',\n",
       " 'Xiaoqian(Cindy) Wu',\n",
       " '\\xe6\\xa2\\x81\\xe6\\xb5\\xb7',\n",
       " 'Zi Bin Cheah',\n",
       " 'octw chen',\n",
       " 'Xiaoqian Cindy Wu',\n",
       " 'John Hax',\n",
       " 'Hawkeyes Wind',\n",
       " '\\xe4\\xb8\\x80\\xe4\\xb8\\x9d',\n",
       " 'Sunruinan',\n",
       " 'Doris Wang',\n",
       " 'Bobby Tung',\n",
       " 'Xidorn Quan',\n",
       " 'Yijun Chen',\n",
       " '\\xe5\\x90\\xb3\\xe6\\x97\\xad\\xe6\\x98\\x8c',\n",
       " 'Cheah Zi Bin',\n",
       " 'Jingtao Liu',\n",
       " 'Hao (Kenny) Lu',\n",
       " 'Zhiqiang Zhang',\n",
       " 'Cindy',\n",
       " 'Kenny',\n",
       " 'Chen Yijun',\n",
       " 'Chunming',\n",
       " '-ambrose']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_name_list(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_signature(message_string):\n",
    "    name_list = []\n",
    "    p = re.compile(ur'\\\"?([\\w\\s\\(\\)]+|[\\x80-\\xff]+)\\\"?\\s<')\n",
    "    msg = mime.from_string(message_string)\n",
    "    for item in msg.headers.items():\n",
    "        if item[0] == 'From':\n",
    "            name = p.search(item[1].encode('utf-8')).group(1)\n",
    "    \n",
    "    if re.split(r'\\s', name):\n",
    "        for i in range(len(re.split()))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
